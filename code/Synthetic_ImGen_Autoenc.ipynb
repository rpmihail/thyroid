{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kbhPLV_J2zUC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import plotly.graph_objs as go\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oB7o-oz_2zUG"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "\n",
    "im_size = (252, 252)\n",
    "\n",
    "\n",
    "# dataset definition\n",
    "class thyroidDataset(Dataset):\n",
    "    def __init__(self, split):\n",
    "        self.all_data = []\n",
    "        self.compositions = {'Unknown':0, 'cystic':1,\n",
    "                             'predominantly solid':2,\n",
    "                             'solid':3, 'spongiform appareance':4}\n",
    "        \n",
    "        self.echogenicities = {'Unknown':0, 'hyperechogenecity':1,\n",
    "                             'hypoechogenecity':2, 'isoechogenicity':3,\n",
    "                             'marked hypoechogenecity':4}\n",
    "        \n",
    "        self.margins = {'Unknown':0, 'ill- defined':1, 'microlobulated':2,\n",
    "                        'spiculated':3, 'well defined smooth':4}\n",
    "        \n",
    "        self.calcifications = {'macrocalcification':0, 'microcalcification':1, 'non':2}\n",
    "        \n",
    "        self.types = {'benign':0, 'malign':1}\n",
    "        \n",
    "        \n",
    "        self.types_count = []\n",
    "        for t_type in ['benign', 'malign']:\n",
    "            root_dir=Path('../data/' + split + '/' + t_type).expanduser().resolve().absolute() \n",
    "            print(root_dir)\n",
    "            files = list(root_dir.glob(\"*\"))\n",
    "            labels = [self.types[t_type]] * len(files)\n",
    "            self.types_count.append(len(files))\n",
    "            data_list = list(zip(files, labels))\n",
    "            self.all_data.extend(data_list)\n",
    "        random.shuffle(self.all_data)\n",
    "        self.cases, self.types = zip(*self.all_data)\n",
    "        print(\"number of data items:\" + str(len(self.cases)))\n",
    "        self.sample_weights = [1/self.types_count[label] for label in self.types]\n",
    "    def __len__(self):\n",
    "        return len(self.cases)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        labels = np.zeros(16, dtype = float)\n",
    "        xml_data = ET.parse(list(self.cases[idx].glob('*[0-9].xml'))[0]).getroot()\n",
    "        for x in xml_data:\n",
    "            if x.tag=='composition' and x.text is not None:\n",
    "                composition = x.text\n",
    "                labels[self.compositions[composition] - 1] = 1.0\n",
    "            if x.tag=='echogenicity' and x.text is not None:\n",
    "                echogenicity = x.text\n",
    "                labels[self.echogenicities[echogenicity] + 3] = 1.0\n",
    "            if x.tag=='margins' and x.text is not None:\n",
    "                margin = x.text\n",
    "                labels[self.margins[margin] + 7] = 1.0\n",
    "            if x.tag=='calcifications' and x.text is not None:\n",
    "                calcification = x.text\n",
    "                labels[self.calcifications[calcification] + 11] = 1.0\n",
    "        xml_data = ET.parse(list(self.cases[idx].glob('*[0-9].xml'))[0]).find(\"mark\")\n",
    "        for x in xml_data:\n",
    "            if(x.tag=='svg'):\n",
    "                encoded = str(x.text)\n",
    "                poly_data = json.loads(x.text)\n",
    "        \n",
    "        labels[15] = list(self.types)[idx]\n",
    "        im_name = list(self.cases[idx].glob('*[0-9].jpg'))[0]\n",
    "        im = cv2.imread(str(im_name))[:, :, 0]\n",
    "        mask = np.zeros(np.shape(im))\n",
    "        im = cv2.resize(im, dsize=im_size, interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # add mask \n",
    "        for polygon in poly_data:\n",
    "            xs = []\n",
    "            ys = []\n",
    "            for point in polygon[\"points\"]:\n",
    "                xs.append(point[\"x\"])\n",
    "                ys.append(point[\"y\"])\n",
    "            contour = np.concatenate((np.expand_dims(xs, 1), np.expand_dims(ys, 1)), axis=1)\n",
    "            cv2.fillPoly(mask, pts = [contour], color =(1, 1, 1))\n",
    "        \n",
    "        #mask = cv2.resize(mask, dsize=(300, 300), interpolation=cv2.INTER_LINEAR)\n",
    "        mask = cv2.resize(mask, dsize=im_size, interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Adding data augmentation to avoid overfitting\n",
    "        if random.randint(1, 10) > 5:\n",
    "            im = np.flipud(im)\n",
    "        if random.randint(1, 10) > 5:\n",
    "            im = np.fliplr(im)\n",
    "        if random.randint(1, 10) > 5:\n",
    "            for i in range(random.randint(1, 4)):\n",
    "                im = np.rot90(im)\n",
    "        im = np.ascontiguousarray(im)\n",
    "\n",
    "        #plt.figure()\n",
    "        #plt.imshow(im)\n",
    "\n",
    "        transforms = Compose([ToTensor()])\n",
    "        mask = transforms(mask)\n",
    "        im = transforms(im)\n",
    "        \n",
    "        im = im * mask\n",
    "        \n",
    "        im = im.type(torch.FloatTensor)\n",
    "        \n",
    "        sample = {\"image\": im, \"labels\": torch.from_numpy(labels), \"types\" : self.types, \"name\": str(im_name)}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSpwWmNT2zUI",
    "outputId": "15e18526-d786-44bb-b283-5de9c2fbadf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mihail/OneDrive/work/projects/thyroid/data/train/benign\n",
      "/home/mihail/OneDrive/work/projects/thyroid/data/train/malign\n",
      "number of data items:73\n",
      "/home/mihail/OneDrive/work/projects/thyroid/data/train/benign\n",
      "/home/mihail/OneDrive/work/projects/thyroid/data/train/malign\n",
      "number of data items:73\n",
      "/home/mihail/OneDrive/work/projects/thyroid/data/test/benign\n",
      "/home/mihail/OneDrive/work/projects/thyroid/data/test/malign\n",
      "number of data items:25\n"
     ]
    }
   ],
   "source": [
    "# Dataset creation\n",
    "training_set = thyroidDataset(split='train')\n",
    "parameters_train = {\n",
    "    \"batch_size\": 32,\n",
    "    #\"shuffle\": True,\n",
    "}\n",
    "\n",
    "parameters_test = {\n",
    "    \"batch_size\": 1,\n",
    "    \"shuffle\": False,\n",
    "}\n",
    "training_set = thyroidDataset(split='train')\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **parameters_train, sampler=torch.utils.data.WeightedRandomSampler(training_set.sample_weights, len(training_set.cases), replacement=True))\n",
    "\n",
    "training_generator1 = torch.utils.data.DataLoader(training_set, **parameters_test, sampler=torch.utils.data.WeightedRandomSampler(training_set.sample_weights, len(training_set.cases), replacement=True))\n",
    "\n",
    "\n",
    "testing_set = thyroidDataset(split='test')\n",
    "testing_generator = torch.utils.data.DataLoader(testing_set, **parameters_test, sampler=torch.utils.data.WeightedRandomSampler(testing_set.sample_weights, len(testing_set.cases), replacement=True))\n",
    "\n",
    "\n",
    "import torch.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSqG6YXbytzm"
   },
   "outputs": [],
   "source": [
    "\n",
    "for item in training_set:\n",
    "  print(np.shape(item[\"labels\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eaYyiCFc2zUJ",
    "outputId": "5039dfad-59ca-4fac-b4b0-d316b0878900"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (decoder_lin): Sequential(\n",
       "    (0): Linear(in_features=48, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=512, out_features=4608, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(512, 3, 3))\n",
       "  (decoder_conv): Sequential(\n",
       "    (0): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (13): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): ConvTranspose2d(8, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "\n",
    "        self.N.loc = self.N.loc.cuda() # hack to get sampling on the GPU\n",
    "        self.N.scale = self.N.scale.cuda()\n",
    "        self.kl = 0\n",
    "\n",
    "\n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True)\n",
    "\n",
    "        )\n",
    "        \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "### Linear section\n",
    "\n",
    "\n",
    "        self.conditional_pipe = nn.Sequential(\n",
    "            nn.Linear(2320, fc2_input_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(fc2_input_dim, encoded_space_dim)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(32, fc2_input_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(fc2_input_dim, encoded_space_dim)\n",
    "        )\n",
    "        self.encoder_lin1 = nn.Sequential(\n",
    "            nn.Linear(32, fc2_input_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(fc2_input_dim, encoded_space_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, c):\n",
    "        #print(\"Encoder input: \", np.shape(x))\n",
    "        x = self.encoder_cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        x = torch.cat([x, c], 1).float()\n",
    "\n",
    "        x = self.conditional_pipe(x)\n",
    "\n",
    "        mu =  self.encoder_lin(x)\n",
    "        sigma = torch.exp(self.encoder_lin1(x))\n",
    "\n",
    "\n",
    "        z = mu + sigma*self.N.sample(mu.shape)\n",
    "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n",
    "\n",
    "        return z\n",
    "    \n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(encoded_space_dim+16, fc2_input_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(fc2_input_dim, 3 * 3 * fc2_input_dim),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, \n",
    "        unflattened_size=(fc2_input_dim, 3, 3))\n",
    "\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(fc2_input_dim, 128, 3, stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2,  padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, labels):\n",
    "\n",
    "        x = inputs = torch.cat([x, labels.float()], 1).float()\n",
    "\n",
    "        x = self.decoder_lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder_conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "loss_latent = torch.nn.L1Loss()\n",
    "\n",
    "\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "lr= 0.001\n",
    "\n",
    "### Set the random seed for reproducible results\n",
    "torch.manual_seed(0)\n",
    "\n",
    "### Initialize the two networks\n",
    "dim = 32\n",
    "\n",
    "#model = Autoencoder(encoded_space_dim=encoded_space_dim)\n",
    "encoder = Encoder(encoded_space_dim=dim,fc2_input_dim=512)\n",
    "decoder = Decoder(encoded_space_dim=dim,fc2_input_dim=512)\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-05)\n",
    "\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9tgkRG3Q2zUL",
    "outputId": "2f3027d2-2e97-4847-ddfd-37543c72baa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 1/100000 \t train loss 118148.390625\n",
      "\n",
      " EPOCH 2/100000 \t train loss 106393.25\n",
      "\n",
      " EPOCH 3/100000 \t train loss 109332.375\n",
      "\n",
      " EPOCH 4/100000 \t train loss 104653.203125\n",
      "\n",
      " EPOCH 5/100000 \t train loss 103560.984375\n",
      "\n",
      " EPOCH 6/100000 \t train loss 102817.6640625\n",
      "\n",
      " EPOCH 7/100000 \t train loss 95075.375\n",
      "\n",
      " EPOCH 8/100000 \t train loss 99739.1953125\n",
      "\n",
      " EPOCH 9/100000 \t train loss 92086.5859375\n",
      "\n",
      " EPOCH 10/100000 \t train loss 92844.6640625\n",
      "\n",
      " EPOCH 11/100000 \t train loss 85545.75\n",
      "\n",
      " EPOCH 12/100000 \t train loss 90165.2734375\n",
      "\n",
      " EPOCH 13/100000 \t train loss 95277.453125\n",
      "\n",
      " EPOCH 14/100000 \t train loss 90064.828125\n",
      "\n",
      " EPOCH 15/100000 \t train loss 87170.6640625\n",
      "\n",
      " EPOCH 16/100000 \t train loss 86809.796875\n",
      "\n",
      " EPOCH 17/100000 \t train loss 86244.4140625\n",
      "\n",
      " EPOCH 18/100000 \t train loss 84000.3046875\n",
      "\n",
      " EPOCH 19/100000 \t train loss 79225.28125\n",
      "\n",
      " EPOCH 20/100000 \t train loss 76997.078125\n",
      "\n",
      " EPOCH 21/100000 \t train loss 77155.7265625\n",
      "\n",
      " EPOCH 22/100000 \t train loss 75273.484375\n",
      "\n",
      " EPOCH 23/100000 \t train loss 71641.5625\n",
      "\n",
      " EPOCH 24/100000 \t train loss 72577.921875\n",
      "\n",
      " EPOCH 25/100000 \t train loss 72099.296875\n",
      "\n",
      " EPOCH 26/100000 \t train loss 70947.953125\n",
      "\n",
      " EPOCH 27/100000 \t train loss 67578.875\n",
      "\n",
      " EPOCH 28/100000 \t train loss 68072.8515625\n",
      "\n",
      " EPOCH 29/100000 \t train loss 68726.6484375\n",
      "\n",
      " EPOCH 30/100000 \t train loss 67036.6171875\n",
      "\n",
      " EPOCH 31/100000 \t train loss 60583.00390625\n",
      "\n",
      " EPOCH 32/100000 \t train loss 61528.9375\n",
      "\n",
      " EPOCH 33/100000 \t train loss 60041.546875\n",
      "\n",
      " EPOCH 34/100000 \t train loss 57935.9609375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9ea474501870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdiz_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Move tensor to the proper device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mimage_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-9383eb135c43>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m#mask = cv2.resize(mask, dsize=(300, 300), interpolation=cv2.INTER_LINEAR)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mim_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 100000\n",
    "diz_loss = {'train_loss':[],'val_loss':[]}\n",
    "for epoch in range(num_epochs):\n",
    "    for data in training_generator: \n",
    "        # Move tensor to the proper device\n",
    "        image_batch = data[\"image\"]\n",
    "        image_batch = image_batch.to(device)\n",
    "\n",
    "        labels = data[\"labels\"].to(device)\n",
    "        \n",
    "        \n",
    "        #print(\"Random data shape\", np.shape(random_data), \"; data[labels] \", np.shape(data[\"labels\"]))\n",
    "        labels = labels.float().to(device)\n",
    "        \n",
    "        #print(latent)\n",
    "        \n",
    "        # Encode data\n",
    "        encoded_data = encoder(image_batch, labels)\n",
    "        \n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data, labels)\n",
    "        # Evaluate loss\n",
    "\n",
    "        #print(\"Encoder.kl : \", encoder.kl)\n",
    "\n",
    "        d = ((image_batch - decoded_data)**2).sum()\n",
    "        loss = d + 0.5*encoder.kl\n",
    "\n",
    "        #loss = loss_fn(decoded_data, image_batch) + 0.2*loss_latent(encoded_data, latent.float())\n",
    "        # Backward pass\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # Print batch loss\n",
    "        #print('\\t partial train loss (single batch): %f' % (loss.data))\n",
    "        #train_loss.append(loss.detach().cpu().numpy())   \n",
    "    print('\\n EPOCH {}/{} \\t train loss {}'.format(epoch + 1, num_epochs,  loss))\n",
    "    diz_loss['train_loss'].append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "BS8WiI0V2zUL",
    "outputId": "ec557cbc-793c-415f-8dc9-80db59551427"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UYc5sl_GQLuw",
    "outputId": "209f122a-4a54-477b-8532-810a822357eb"
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_qAa0yxB2zUN",
    "outputId": "94ed2015-391e-49e9-d758-443104a900ad"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(20, 5, figsize=(10, 40))\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "c = 0\n",
    "for data in testing_generator: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "    # Move tensor to the proper device\n",
    "    \n",
    "    labels = data[\"labels\"].float().to(device)\n",
    "    \n",
    "    if(c>=20):\n",
    "        break\n",
    "    image_batch = data[\"image\"]\n",
    "\n",
    "    ax[c, 0].imshow(image_batch[0, 0, :, :])\n",
    "\n",
    "    #print(\"Random data shape\", np.shape(random_data), \"; data[labels] \", np.shape(data[\"labels\"]))\n",
    "    for i in range(4):\n",
    "        latent = torch.FloatTensor(np.random.randn(1,dim)).to(device)\n",
    "        img_recon = decoder(latent, labels)\n",
    "        img_recon = img_recon.detach().cpu().numpy()\n",
    "        ax[c, 1+i].imshow(img_recon[0, 0, :, :])\n",
    "    \n",
    "    c += 1\n",
    "    \n",
    "\n",
    "plt.tight_layout()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yc1coh862zUN"
   },
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), \"./encoder.dict\")\n",
    "torch.save(decoder.state_dict(), \"./decoder.dict\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Synthetic_ImGen_Autoenc.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
