{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import plotly.graph_objs as go\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[2]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class thyroidDataset(Dataset):\n",
    "    def __init__(self, split):\n",
    "        self.all_data = []\n",
    "        self.compositions = {'Unknown':0, 'cystic':1,\n",
    "                             'predominantly solid':2,\n",
    "                             'solid':3, 'spongiform appareance':4}\n",
    "        self.echogenicities = {'Unknown':0, 'hyperechogenecity':1,\n",
    "                             'hypoechogenecity':2, 'isoechogenicity':3,\n",
    "                             'marked hypoechogenecity':4}\n",
    "        self.margins = {'Unknown':0, 'ill- defined':1, 'microlobulated':2,\n",
    "                        'spiculated':3, 'well defined smooth':4}\n",
    "        self.calcifications = {'macrocalcification':0, 'microcalcification':1, 'non':2}\n",
    "        self.types ={'benign':0, 'malign':1}\n",
    "        for t_type in ['benign', 'malign']:\n",
    "            root_dir=Path('../data/' + split + '/' + t_type).expanduser().resolve().absolute() \n",
    "            print(root_dir)\n",
    "            files = list(root_dir.glob(\"*\"))\n",
    "            labels = [self.types[t_type]] * len(files)\n",
    "            data_list = list(zip(files, labels))\n",
    "            self.all_data.extend(data_list)\n",
    "        random.shuffle(self.all_data)\n",
    "        self.cases, self.types = zip(*self.all_data)\n",
    "        print(\"number of data items:\" + str(len(self.cases)))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.cases)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        labels = np.zeros(16, dtype = float)\n",
    "        xml_data = ET.parse(list(self.cases[idx].glob('*[0-9].xml'))[0]).getroot()\n",
    "        for x in xml_data:\n",
    "            if x.tag=='composition' and x.text is not None:\n",
    "                composition = x.text\n",
    "                if self.compositions[composition] > 0:\n",
    "                    labels[self.compositions[composition] - 1] = 1.0\n",
    "            if x.tag=='echogenicity' and x.text is not None:\n",
    "                echogenicity = x.text\n",
    "                if self.echogenicities[echogenicity] > 0:\n",
    "                    labels[self.echogenicities[echogenicity] + 3] = 1.0\n",
    "            if x.tag=='margins' and x.text is not None:\n",
    "                margin = x.text\n",
    "                if self.margins[margin] > 0:\n",
    "                    labels[self.margins[margin] + 7] = 1.0\n",
    "            if x.tag=='calcifications' and x.text is not None:\n",
    "                calcification = x.text\n",
    "                labels[self.calcifications[calcification] + 12] = 1.0\n",
    "        \n",
    "        labels[15] = list(self.types)[idx]\n",
    "        im_name = list(self.cases[idx].glob('*[0-9].jpg'))[0]\n",
    "        im = cv2.imread(str(im_name))\n",
    "        im = cv2.resize(im, dsize=(300, 300), interpolation=cv2.INTER_CUBIC)\n",
    "        # Adding data augmentation to avoid overfitting\n",
    "        im = np.ascontiguousarray(im)\n",
    "        transforms = Compose([ToTensor()])\n",
    "        im = transforms(im)\n",
    "        sample = {\"image\": im, \"labels\": torch.from_numpy(labels), \"types\" : self.types }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ahana/thyroid/data/train/benign\n",
      "/home/ahana/thyroid/data/train/malign\n",
      "number of data items:73\n",
      "/home/ahana/thyroid/data/train/benign\n",
      "/home/ahana/thyroid/data/train/malign\n",
      "number of data items:73\n"
     ]
    }
   ],
   "source": [
    "training_set = thyroidDataset(split='train')\n",
    "parameters_train = {\n",
    "    \"batch_size\": 8,\n",
    "    \"shuffle\": True,\n",
    "}\n",
    "parameters_test = {\n",
    "    \"batch_size\": 1,\n",
    "    \"shuffle\": False,\n",
    "}\n",
    "training_set = thyroidDataset(split='train')\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **parameters_train)\n",
    "totiter = len(training_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[60]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 10 # groups\n",
    "a = 15\n",
    "k = 5 # top k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.random.randn(z, a)\n",
    "W = np.random.randn(z, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def projection_simplex_sort(v, z=1):\n",
    "    n_features = v.size(1)\n",
    "    u,_ = torch.sort(v, descending=True)\n",
    "    cssv = torch.cumsum(u,1) - z\n",
    "    ind = torch.arange(n_features).type_as(v) + 1\n",
    "    cond = u - cssv / ind > 0\n",
    "    #rho = ind[cond][-1]\n",
    "    rho,ind_rho = (ind*cond).max(1)\n",
    "    #theta = cssv[cond][-1] / float(rho)\n",
    "    theta = torch.gather(cssv,1,ind_rho[:,None]) / rho[:,None]\n",
    "    w = torch.clamp(v - theta, min=0)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, G, W):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 10, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(14400, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 15)\n",
    "        \n",
    "        self.G_ = torch.nn.Parameter(G)\n",
    "        self.W_ = torch.nn.Parameter(W)\n",
    "        #self.CNN_ = torch.nn.Parameter(CNN)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, x):\n",
    "            \n",
    "        x = self.pool(F.tanh(self.conv1(x)))\n",
    "        x = self.pool(F.tanh(self.conv2(x)))\n",
    "        x = self.pool(F.tanh(self.conv3(x)))\n",
    "        x = self.pool(F.tanh(self.conv4(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        x = torch.unsqueeze(x, 2)\n",
    "        \n",
    "        g = torch.matmul(self.G_, x) \n",
    "        \n",
    "        g = g.repeat((1, 1, k))\n",
    "        \n",
    "        y = g * self.W_\n",
    "        \n",
    "        y, _ = y.max(axis=2)\n",
    "        \n",
    "        y = torch.transpose(y, 1, 0)\n",
    "        \n",
    "        y = torch.sum(y, axis=0)\n",
    "        \n",
    "        return (torch.sigmoid(y), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "net(\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(10, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=14400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = net(torch.FloatTensor(G), torch.FloatTensor(W))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.L1Loss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion1 = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_tr = torch.from_numpy(y_train).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "odel.load_state_dict(torch.load(f'../data/models/end_to_end_v2.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30376/2628310563.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx_im_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_im_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_im_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# this needs work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \"\"\"\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for data in training_generator:\n",
    "        #model.train(True)\n",
    "        x_im_train = data[\"image\"]\n",
    "        if(np.shape(x_im_train)[0]==1):\n",
    "            continue\n",
    "        y_im_train = data[\"labels\"][:, 15].to(device)\n",
    "        x_im_train = x_im_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        (y_pred, attributes_pred) = model(x_im_train)\n",
    "        \n",
    "        # this needs work \n",
    "        # loss = criterion(torch.squeeze(y_pred.to(float)), torch.squeeze(y_im_train.to(float))) + criterion1(torch.squeeze(attributes_pred.to(float)), data[\"labels\"][:, :15].to(device))\n",
    "        loss = criterion1(torch.squeeze(attributes_pred.to(float)), data[\"labels\"][:, :15].to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.G_.data = projection_simplex_sort(model.G_.data)\n",
    "        running_loss += loss.item()\n",
    "    epoch = epoch + 1\n",
    "    print(\"Epoch: \", epoch, \"; running-loss: \", running_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[44]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../data/models/end_to_end_v3.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[57]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " VISUALIZE model output and parameters on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_test = {\n",
    "    \"batch_size\": 1,\n",
    "    \"shuffle\": False,\n",
    "}\n",
    "test_set = thyroidDataset(split='test')\n",
    "test_generator = torch.utils.data.DataLoader(test_set, **parameters_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "ground_truth = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_pred = []\n",
    "attr_gt = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for data in test_generator:\n",
    "    y_im_test = data[\"labels\"][:, 15].to(device)\n",
    "    x_im_test = data[\"image\"]\n",
    "    \n",
    "    x_im_test = x_im_test.to(device)\n",
    "    \n",
    "    (y_pred, attributes_pred) = model(x_im_test)\n",
    "    \n",
    "    attr_pred.append(attributes_pred.detach().cpu().numpy())\n",
    "    \n",
    "    attr_gt.append(data[\"labels\"][:, :15].detach().cpu().numpy())\n",
    "    \n",
    "    \n",
    "    predicted.append(np.squeeze(y_pred.detach().cpu().numpy()))\n",
    "    ground_truth.append(np.squeeze(y_im_test.detach().cpu().numpy()))\n",
    "    count += 1\n",
    "        \n",
    "predicted = np.expand_dims(np.array(predicted), 1)\n",
    "ground_truth = np.expand_dims(np.array(ground_truth), 1)\n",
    "viz = (np.concatenate((ground_truth, predicted), axis=1)>0.5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(viz)\n",
    "plt.title(\"Left col: gt; Right col: pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_perc = np.sum(np.abs(viz[:, 0] - viz[:, 1])) / np.size(viz[:, 0])\n",
    "err_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[46]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[58]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ALL this should be on TEST set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_pred = np.squeeze(np.array(attr_pred))\n",
    "attr_gt = np.squeeze(np.array(attr_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax1 = fig.add_subplot(231)    # The big subplot\n",
    "ax2 = fig.add_subplot(232)\n",
    "ax3 = fig.add_subplot(233)\n",
    "ax4 = fig.add_subplot(234)\n",
    "ax5 = fig.add_subplot(235)\n",
    "ax6 = fig.add_subplot(236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1.imshow(attr_gt)\n",
    "ax1.set_title(\"Attributes Ground Truth\")\n",
    "ax2.imshow((attr_pred > 0.5) * 1)\n",
    "ax2.set_title(\"Attributes Predicted and Thresholded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax3.imshow(np.expand_dims(viz[:, 0], 1))\n",
    "ax3.set_title(\"Label (malign or benign)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax4.imshow(attr_gt)\n",
    "ax4.set_title(\"Attributes Ground Truth\")\n",
    "ax5.imshow(attr_pred )\n",
    "ax5.set_title(\"Attributes Predicted Soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax6.imshow(np.expand_dims(viz[:, 0], 1))\n",
    "ax6.set_title(\"Label (malign or benign)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout(pad=0.6, w_pad=0, h_pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[59]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = model.G_.data.detach().cpu().numpy()\n",
    "plt.imshow(G)\n",
    "plt.title(\"Group attribute probabilites (G Matrix)\")\n",
    "plt.ylabel(\"Group\")\n",
    "plt.xlabel(\"Attribute probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[60]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = [i % a for i in range(z*a)]\n",
    "target = [(i // 15) + 15 for i in range(z*a)]\n",
    "G[G < 0.05] = 0.0\n",
    "value = G.flatten().tolist()\n",
    "print(len(source), len(target), len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_node = [\n",
    "              '#808080', '#808080', '#808080', '#808080', '#808080',\n",
    "              '#808080', '#808080', '#808080', '#808080', '#808080',\n",
    "              '#808080', '#808080', '#808080', '#808080', '#808080',\n",
    "              '#FF0000', '#FFFF00', '#00FF00', '#00FFFF', '#FF00FF',\n",
    "              '#00CED1', '#FF8C00', '#BDB76B', '#2F4F4F', '#B8860B'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_link = []\n",
    "link_colors = ['#F08080', '#FFFACD', '#98FB98', '#87CEFA', '#EE82EE',\n",
    "              '#AFEEEE', '#FFA500', '#F0E68C', '#708090', '#DAA520']\n",
    "for i in range(z):\n",
    "    color_link.extend([link_colors[i]] * a)\n",
    "print(color_link)\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 20,\n",
    "      #line = dict(color = \"black\", width = 0.5),\n",
    "      color = color_node,\n",
    "      label = [\"cystic\", \"mostly solid\", \"solid\", \"spongiform\",\n",
    "               \"hyper\", \"hypo\", \"iso\", \"marked\",\n",
    "               \"ill-defined\", \"micro\", \"spiculated\", \"smooth\",\n",
    "               \"macro\", \"micro\", \"non\",\n",
    "               \"G1\", \"G2\", \"G3\", \"G4\", \"G5\",\n",
    "               \"G6\", \"G7\", \"G8\", \"G9\", \"G10\"],\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = source, # indices correspond to labels, eg A1, A2, A1, B1, ...\n",
    "      target = target,\n",
    "      value = value,\n",
    "      color = color_link\n",
    "  ))])\n",
    "fig.update_layout(title_text=\"Basic Sankey Diagram\", font_size=10)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
