{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kbhPLV_J2zUC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import plotly.graph_objs as go\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eaYyiCFc2zUJ",
    "outputId": "5039dfad-59ca-4fac-b4b0-d316b0878900"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (decoder_lin): Sequential(\n",
       "    (0): Linear(in_features=48, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=512, out_features=4608, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(512, 3, 3))\n",
       "  (decoder_conv): Sequential(\n",
       "    (0): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (13): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): ConvTranspose2d(8, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "\n",
    "        self.N.loc = self.N.loc.cuda() # hack to get sampling on the GPU\n",
    "        self.N.scale = self.N.scale.cuda()\n",
    "        self.kl = 0\n",
    "\n",
    "\n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True)\n",
    "\n",
    "        )\n",
    "        \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "### Linear section\n",
    "\n",
    "\n",
    "        self.conditional_pipe = nn.Sequential(\n",
    "            nn.Linear(2320, fc2_input_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(fc2_input_dim, encoded_space_dim)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(32, fc2_input_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(fc2_input_dim, encoded_space_dim)\n",
    "        )\n",
    "        self.encoder_lin1 = nn.Sequential(\n",
    "            nn.Linear(32, fc2_input_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(fc2_input_dim, encoded_space_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, c):\n",
    "        #print(\"Encoder input: \", np.shape(x))\n",
    "        x = self.encoder_cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        x = torch.cat([x, c], 1).float()\n",
    "\n",
    "        x = self.conditional_pipe(x)\n",
    "\n",
    "        mu =  self.encoder_lin(x)\n",
    "        sigma = torch.exp(self.encoder_lin1(x))\n",
    "\n",
    "\n",
    "        z = mu + sigma*self.N.sample(mu.shape)\n",
    "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n",
    "\n",
    "        return z\n",
    "    \n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(encoded_space_dim+16, fc2_input_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(fc2_input_dim, 3 * 3 * fc2_input_dim),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, \n",
    "        unflattened_size=(fc2_input_dim, 3, 3))\n",
    "\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(fc2_input_dim, 128, 3, stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2,  padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, labels):\n",
    "\n",
    "        x = inputs = torch.cat([x, labels.float()], 1).float()\n",
    "\n",
    "        x = self.decoder_lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder_conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "loss_latent = torch.nn.L1Loss()\n",
    "\n",
    "\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "lr= 0.001\n",
    "\n",
    "### Set the random seed for reproducible results\n",
    "torch.manual_seed(0)\n",
    "\n",
    "### Initialize the two networks\n",
    "dim = 32\n",
    "\n",
    "#model = Autoencoder(encoded_space_dim=encoded_space_dim)\n",
    "encoder = Encoder(encoded_space_dim=dim,fc2_input_dim=512)\n",
    "decoder = Decoder(encoded_space_dim=dim,fc2_input_dim=512)\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-05)\n",
    "\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9tgkRG3Q2zUL",
    "outputId": "2f3027d2-2e97-4847-ddfd-37543c72baa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.load_state_dict(torch.load(\"decoder.dict\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def generate_label():\n",
    "    \n",
    "    label = np.zeros((1, 16))\n",
    "    \n",
    "    comp = np.random.randint(4)\n",
    "    echo = np.random.randint(4)\n",
    "    margins = np.random.randint(4)\n",
    "    calc = np.random.randint(3)\n",
    "    \n",
    "    label[0,comp] = 1\n",
    "    label[0,4+echo] = 1\n",
    "    label[0,7+margins] = 1\n",
    "    label[0,13+calc] = 1\n",
    "    \n",
    "    return label\n",
    "\n",
    "# 0 1 2 3 |4 5 6 7 | 10 11 12 13 | 15 16\n",
    "\n",
    "\n",
    "print(generate_label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_qAa0yxB2zUN",
    "outputId": "94ed2015-391e-49e9-d758-443104a900ad"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(20, 5, figsize=(10, 40))\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "for c in range(20): # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "    # Move tensor to the proper device\n",
    "    \n",
    "    labels = torch.FloatTensor(generate_label()).to(device)\n",
    "    \n",
    "    #print(\"Random data shape\", np.shape(random_data), \"; data[labels] \", np.shape(data[\"labels\"]))\n",
    "    for i in range(5):\n",
    "        latent = torch.FloatTensor(np.random.randn(1, dim)).to(device)\n",
    "        img_recon = decoder(latent, labels)\n",
    "        img_recon = img_recon.detach().cpu().numpy()\n",
    "        ax[c, i].imshow(img_recon[0, 0, :, :])\n",
    "    \n",
    "    \n",
    "\n",
    "plt.tight_layout()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Synthetic_ImGen_Autoenc.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
